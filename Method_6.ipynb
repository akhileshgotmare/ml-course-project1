{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '/Users/akhileshgotmare/Desktop/Git_Junta/data-ml-course-project1/train.csv' # TODO: download train data and supply path here \n",
    "y, X, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "\n",
    "def standardize_badFeatures(X):\n",
    "    \n",
    "    # Function that calculate the mean and std of bad features without elements equal to -999\n",
    "    # Then, it replaces -999 values by zeros, zeros won't influence the train of the model... \n",
    "    mean_x = np.zeros((X.shape[1],))\n",
    "    std_x = np.zeros((X.shape[1],))\n",
    "    for d in range(X.shape[1]):\n",
    "        idx = np.where(X[:,d] == -999)[0]\n",
    "        mean_x[d] = np.mean(np.delete(X[:,d], (idx)))\n",
    "        std_x[d] = np.std(np.delete(X[:,d], (idx)))\n",
    "        X[:,d] = (X[:,d]-mean_x[d])/std_x[d]\n",
    "        X[idx,d] = 0\n",
    "    return X, mean_x, std_x\n",
    "\n",
    "\n",
    "def clean_data(X):\n",
    "\n",
    "    # find indices of features that have at least one value -999, we call them \"bad\" features\n",
    "    idx_badFeatures = []\n",
    "    for d in range(X.shape[1]):\n",
    "        if sum(X[:,d] == -999) > 0:\n",
    "            idx_badFeatures.append(d)\n",
    "\n",
    "    # separate \"good\" and \"bad\" features\n",
    "    X_badFeatures = X[:,idx_badFeatures]\n",
    "    X_goodFeatures = np.delete(X,(idx_badFeatures), axis=1)\n",
    "\n",
    "    # Standardize it differently (see : standardize_badFeatures(X))\n",
    "    tX, mean_x, std_x = standardize(X_goodFeatures)\n",
    "    tX2, mean_x2, std_x2 = standardize_badFeatures(X_badFeatures)\n",
    "\n",
    "    # comment the 3 next lines if you want to work only with \"good\" features\n",
    "    tX = np.hstack((tX, tX2))\n",
    "    mean_x = np.hstack((mean_x, mean_x2))\n",
    "    std_x = np.hstack((std_x, std_x2))\n",
    "    \n",
    "    return tX, mean_x, std_x\n",
    "\n",
    "# Now tX already has ones in the first column...\n",
    "tX, mean_x, std_x = clean_data(X)\n",
    "X=tX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y[np.where(y == -1)[0]] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Penalized logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 33.46867866,  20.70679819,   3.17998352, ...,   3.24552249,\n",
       "         3.83250566,   3.94738714])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sigma(a):\n",
    "    \n",
    "    sig=np.zeros([a.shape[0]],)\n",
    "    \n",
    "    for i in range(a.shape[0]):\n",
    "        if a[i]>100:\n",
    "            sig[i] = 1\n",
    "        elif a[i]<-100:\n",
    "            sig[i] = 0\n",
    "        else:\n",
    "            sig[i]=np.exp(a[i])/(1+ np.exp(a[i]))\n",
    "        \n",
    "                \n",
    "    \n",
    "    \n",
    "    \n",
    "    return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0\n",
      "0 1\n",
      "1\n",
      "0 2\n",
      "2\n",
      "0 3\n",
      "3\n",
      "0 4\n",
      "4\n",
      "0 5\n",
      "5\n",
      "0 6\n",
      "6\n",
      "0 7\n",
      "7\n",
      "0 8\n",
      "8\n",
      "0 9\n",
      "9\n",
      "0 10\n",
      "10\n",
      "0 11\n",
      "11\n",
      "0 12\n",
      "12\n",
      "0 13\n",
      "13\n",
      "0 14\n",
      "14\n",
      "1 0\n",
      "15\n",
      "1 1\n",
      "16\n",
      "1 2\n",
      "17\n",
      "1 3\n",
      "18\n",
      "1 4\n",
      "19\n",
      "1 5\n",
      "20\n",
      "1 6\n",
      "21\n",
      "1 7\n",
      "22\n",
      "1 8\n",
      "23\n",
      "1 9\n",
      "24\n",
      "1 10\n",
      "25\n",
      "1 11\n",
      "26\n",
      "1 12\n",
      "27\n",
      "1 13\n",
      "28\n",
      "1 14\n",
      "29\n",
      "2 0\n",
      "30\n",
      "2 1\n",
      "31\n",
      "2 2\n",
      "32\n",
      "2 3\n",
      "33\n",
      "2 4\n",
      "34\n",
      "2 5\n",
      "35\n",
      "2 6\n",
      "36\n",
      "2 7\n",
      "37\n",
      "2 8\n",
      "38\n",
      "2 9\n",
      "39\n",
      "2 10\n",
      "40\n",
      "2 11\n",
      "41\n",
      "2 12\n",
      "42\n",
      "2 13\n",
      "43\n",
      "2 14\n",
      "44\n",
      "3 0\n",
      "45\n",
      "3 1\n",
      "46\n",
      "3 2\n",
      "47\n",
      "3 3\n",
      "48\n",
      "3 4\n",
      "49\n",
      "3 5\n",
      "50\n",
      "3 6\n",
      "51\n",
      "3 7\n",
      "52\n",
      "3 8\n",
      "53\n",
      "3 9\n",
      "54\n",
      "3 10\n",
      "55\n",
      "3 11\n",
      "56\n",
      "3 12\n",
      "57\n",
      "3 13\n",
      "58\n",
      "3 14\n",
      "59\n",
      "4 0\n",
      "60\n",
      "4 1\n",
      "61\n",
      "4 2\n",
      "62\n",
      "4 3\n",
      "63\n",
      "4 4\n",
      "64\n",
      "4 5\n",
      "65\n",
      "4 6\n",
      "66\n",
      "4 7\n",
      "67\n",
      "4 8\n",
      "68\n",
      "4 9\n",
      "69\n",
      "4 10\n",
      "70\n",
      "4 11\n",
      "71\n",
      "4 12\n",
      "72\n",
      "4 13\n",
      "73\n",
      "4 14\n",
      "74\n",
      "5 0\n",
      "75\n",
      "5 1\n",
      "76\n",
      "5 2\n",
      "77\n",
      "5 3\n",
      "78\n",
      "5 4\n",
      "79\n",
      "5 5\n",
      "80\n",
      "5 6\n",
      "81\n",
      "5 7\n",
      "82\n",
      "5 8\n",
      "83\n",
      "5 9\n",
      "84\n",
      "5 10\n",
      "85\n",
      "5 11\n",
      "86\n",
      "5 12\n",
      "87\n",
      "5 13\n",
      "88\n",
      "5 14\n",
      "89\n",
      "6 0\n",
      "90\n",
      "6 1\n",
      "91\n",
      "6 2\n",
      "92\n",
      "6 3\n",
      "93\n",
      "6 4\n",
      "94\n",
      "6 5\n",
      "95\n",
      "6 6\n",
      "96\n",
      "6 7\n",
      "97\n",
      "6 8\n",
      "98\n",
      "6 9\n",
      "99\n",
      "6 10\n",
      "100\n",
      "6 11\n",
      "101\n",
      "6 12\n",
      "102\n",
      "6 13\n",
      "103\n",
      "6 14\n",
      "104\n",
      "7 0\n",
      "105\n",
      "7 1\n",
      "106\n",
      "7 2\n",
      "107\n",
      "7 3\n",
      "108\n",
      "7 4\n",
      "109\n",
      "7 5\n",
      "110\n",
      "7 6\n",
      "111\n",
      "7 7\n",
      "112\n",
      "7 8\n",
      "113\n",
      "7 9\n",
      "114\n",
      "7 10\n",
      "115\n",
      "7 11\n",
      "116\n",
      "7 12\n",
      "117\n",
      "7 13\n",
      "118\n",
      "7 14\n",
      "119\n",
      "8 0\n",
      "120\n",
      "8 1\n",
      "121\n",
      "8 2\n",
      "122\n",
      "8 3\n",
      "123\n",
      "8 4\n",
      "124\n",
      "8 5\n",
      "125\n",
      "8 6\n",
      "126\n",
      "8 7\n",
      "127\n",
      "8 8\n",
      "128\n",
      "8 9\n",
      "129\n",
      "8 10\n",
      "130\n",
      "8 11\n",
      "131\n",
      "8 12\n",
      "132\n",
      "8 13\n",
      "133\n",
      "8 14\n",
      "134\n",
      "9 0\n",
      "135\n",
      "9 1\n",
      "136\n",
      "9 2\n",
      "137\n",
      "9 3\n",
      "138\n",
      "9 4\n",
      "139\n",
      "9 5\n",
      "140\n",
      "9 6\n",
      "141\n",
      "9 7\n",
      "142\n",
      "9 8\n",
      "143\n",
      "9 9\n",
      "144\n",
      "9 10\n",
      "145\n",
      "9 11\n",
      "146\n",
      "9 12\n",
      "147\n",
      "9 13\n",
      "148\n",
      "9 14\n",
      "149\n",
      "10 0\n",
      "150\n",
      "10 1\n",
      "151\n",
      "10 2\n",
      "152\n",
      "10 3\n",
      "153\n",
      "10 4\n",
      "154\n",
      "10 5\n",
      "155\n",
      "10 6\n",
      "156\n",
      "10 7\n",
      "157\n",
      "10 8\n",
      "158\n",
      "10 9\n",
      "159\n",
      "10 10\n",
      "160\n",
      "10 11\n",
      "161\n",
      "10 12\n",
      "162\n",
      "10 13\n",
      "163\n",
      "10 14\n",
      "164\n",
      "11 0\n",
      "165\n",
      "11 1\n",
      "166\n",
      "11 2\n",
      "167\n",
      "11 3\n",
      "168\n",
      "11 4\n",
      "169\n",
      "11 5\n",
      "170\n",
      "11 6\n",
      "171\n",
      "11 7\n",
      "172\n",
      "11 8\n",
      "173\n",
      "11 9\n",
      "174\n",
      "11 10\n",
      "175\n",
      "11 11\n",
      "176\n",
      "11 12\n",
      "177\n",
      "11 13\n",
      "178\n",
      "11 14\n",
      "179\n",
      "12 0\n",
      "180\n",
      "12 1\n",
      "181\n",
      "12 2\n",
      "182\n",
      "12 3\n",
      "183\n",
      "12 4\n",
      "184\n",
      "12 5\n",
      "185\n",
      "12 6\n",
      "186\n",
      "12 7\n",
      "187\n",
      "12 8\n",
      "188\n",
      "12 9\n",
      "189\n",
      "12 10\n",
      "190\n",
      "12 11\n",
      "191\n",
      "12 12\n",
      "192\n",
      "12 13\n",
      "193\n",
      "12 14\n",
      "194\n",
      "13 0\n",
      "195\n",
      "13 1\n",
      "196\n",
      "13 2\n",
      "197\n",
      "13 3\n",
      "198\n",
      "13 4\n",
      "199\n",
      "13 5\n",
      "200\n",
      "13 6\n",
      "201\n",
      "13 7\n",
      "202\n",
      "13 8\n",
      "203\n",
      "13 9\n",
      "204\n",
      "13 10\n",
      "205\n",
      "13 11\n",
      "206\n",
      "13 12\n",
      "207\n",
      "13 13\n",
      "208\n",
      "13 14\n",
      "209\n",
      "14 0\n",
      "210\n",
      "14 1\n",
      "211\n",
      "14 2\n",
      "212\n",
      "14 3\n",
      "213\n",
      "14 4\n",
      "214\n",
      "14 5\n",
      "215\n",
      "14 6\n",
      "216\n",
      "14 7\n",
      "217\n",
      "14 8\n",
      "218\n",
      "14 9\n",
      "219\n",
      "14 10\n",
      "220\n",
      "14 11\n",
      "221\n",
      "14 12\n",
      "222\n",
      "14 13\n",
      "223\n",
      "14 14\n",
      "224\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "\n",
    "\n",
    "m=15\n",
    "n=15\n",
    "P = np.zeros([m+1,n+1])\n",
    " \n",
    "max_degree=m-1\n",
    "gamma = 0.01\n",
    "\n",
    "import random\n",
    "import myFunctions as my\n",
    "ws=[]\n",
    "\n",
    "megacounter = 0\n",
    "for degree in range(m):\n",
    "    j=0\n",
    "    for lamb in np.logspace(-5, 2, n):\n",
    "        print(i,j)\n",
    "        print(megacounter)\n",
    "        megacounter+=1\n",
    "        max_iters = 600\n",
    "        \n",
    "        nums = [x for x in range(X.shape[0])]\n",
    "        random.shuffle(nums)\n",
    "\n",
    "        #row_r1 = a[1, :] \n",
    "        stop=int(X.shape[0]/10)\n",
    "        \n",
    "        X_test = X[nums[0:stop],:]\n",
    "        X_train = X[nums[stop+1:-1],:]\n",
    "        \n",
    "        y_test = y[nums[0:stop]]\n",
    "        y_train = y[nums[stop+1:-1]]\n",
    "        \n",
    "        \n",
    "        X_test_poly = my.build_poly(X_test, degree)\n",
    "        X_train_poly = my.build_poly(X_train, degree)\n",
    "        \n",
    "        \n",
    "        initial_w=np.random.random([X_train_poly.shape[1]],)\n",
    "        w=initial_w\n",
    "        \n",
    "        for n_iter in range(max_iters):\n",
    "            \n",
    "            #print(i,j)\n",
    "            #print(n_iter)\n",
    "            gradient = X_train_poly.T.dot(sigma(X_train_poly.dot(w)) - y_train) + 2*lamb*w\n",
    "            w = w - gamma*gradient\n",
    "        \n",
    "        y_test_predict = X_test_poly.dot(w) \n",
    "        y_test_predict[np.where(y_test_predict >= 0.5)[0]] = 1\n",
    "        y_test_predict[np.where(y_test_predict <= 0.5)[0]] = 0\n",
    "        \n",
    "        error = len(np.nonzero(y_test_predict-y_test)[0])/len(y_test)\n",
    "        performance = 1 - error\n",
    "        \n",
    "        P[i,j] = performance\n",
    "        \n",
    "        ws.append(np.copy(w))\n",
    "            \n",
    "        j+= 1\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.65304,  0.6566 ,  0.34236,  0.66288,  0.33988,  0.33584,\n",
       "         0.34116,  0.3434 ,  0.66044,  0.66128,  0.65688,  0.65544,\n",
       "         0.34344,  0.34336,  0.34392,  0.     ],\n",
       "       [ 0.69172,  0.69468,  0.69956,  0.6912 ,  0.68876,  0.6948 ,\n",
       "         0.6924 ,  0.69528,  0.69184,  0.70376,  0.71088,  0.71408,\n",
       "         0.67224,  0.6502 ,  0.62964,  0.     ],\n",
       "       [ 0.73744,  0.74592,  0.74264,  0.74852,  0.74648,  0.729  ,\n",
       "         0.73472,  0.72304,  0.71264,  0.7364 ,  0.67832,  0.662  ,\n",
       "         0.657  ,  0.35728,  0.34356,  0.     ],\n",
       "       [ 0.74196,  0.74004,  0.761  ,  0.74344,  0.67628,  0.72332,\n",
       "         0.7746 ,  0.75244,  0.72612,  0.7576 ,  0.66948,  0.64476,\n",
       "         0.71228,  0.67712,  0.5292 ,  0.     ],\n",
       "       [ 0.75296,  0.74544,  0.74604,  0.73184,  0.73256,  0.74648,\n",
       "         0.75976,  0.7662 ,  0.60868,  0.72108,  0.68916,  0.51392,\n",
       "         0.52484,  0.57804,  0.34384,  0.     ],\n",
       "       [ 0.57868,  0.58016,  0.58072,  0.57736,  0.581  ,  0.6834 ,\n",
       "         0.57732,  0.5876 ,  0.59376,  0.70648,  0.56996,  0.57568,\n",
       "         0.44764,  0.49716,  0.52432,  0.     ],\n",
       "       [ 0.46528,  0.46352,  0.47176,  0.46548,  0.67964,  0.45992,\n",
       "         0.46728,  0.46952,  0.47696,  0.5584 ,  0.41684,  0.43984,\n",
       "         0.55188,  0.44636,  0.33924,  0.     ],\n",
       "       [ 0.56124,  0.56392,  0.5594 ,  0.57016,  0.561  ,  0.5644 ,\n",
       "         0.56832,  0.56276,  0.56304,  0.53368,  0.53488,  0.56436,\n",
       "         0.57408,  0.54428,  0.51176,  0.     ],\n",
       "       [ 0.55352,  0.57612,  0.6074 ,  0.42076,  0.42472,  0.56564,\n",
       "         0.42052,  0.42832,  0.43612,  0.45696,  0.426  ,  0.4474 ,\n",
       "         0.66476,  0.63628,  0.34208,  0.     ],\n",
       "       [ 0.46004,  0.5668 ,  0.56348,  0.566  ,  0.57176,  0.563  ,\n",
       "         0.572  ,  0.56416,  0.57316,  0.56436,  0.46844,  0.49568,\n",
       "         0.55956,  0.54676,  0.52456,  0.     ],\n",
       "       [ 0.403  ,  0.58624,  0.41008,  0.40272,  0.40196,  0.40876,\n",
       "         0.61836,  0.411  ,  0.4096 ,  0.43872,  0.54512,  0.48324,\n",
       "         0.4794 ,  0.42068,  0.33984,  0.     ],\n",
       "       [ 0.5514 ,  0.56028,  0.55784,  0.56656,  0.56316,  0.56336,\n",
       "         0.56384,  0.56364,  0.563  ,  0.5682 ,  0.53024,  0.56012,\n",
       "         0.55876,  0.55828,  0.52904,  0.     ],\n",
       "       [ 0.38828,  0.3992 ,  0.39532,  0.39844,  0.65988,  0.40044,\n",
       "         0.39004,  0.40304,  0.40536,  0.4166 ,  0.50108,  0.38996,\n",
       "         0.62308,  0.51924,  0.34236,  0.     ],\n",
       "       [ 0.55476,  0.5562 ,  0.5626 ,  0.52312,  0.5564 ,  0.55984,\n",
       "         0.53256,  0.56328,  0.49792,  0.55464,  0.57048,  0.55712,\n",
       "         0.44348,  0.54788,  0.52788,  0.     ],\n",
       "       [ 0.39144,  0.39436,  0.59132,  0.3908 ,  0.3956 ,  0.39592,\n",
       "         0.3934 ,  0.39392,  0.39488,  0.40524,  0.46432,  0.48916,\n",
       "         0.38976,  0.40468,  0.33564,  0.     ],\n",
       "       [ 0.     ,  0.     ,  0.     ,  0.     ,  0.     ,  0.     ,\n",
       "         0.     ,  0.     ,  0.     ,  0.     ,  0.     ,  0.     ,\n",
       "         0.     ,  0.     ,  0.     ,  0.     ]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77459999999999996"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P[3,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91,)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws[51].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-05\n",
      "3.16227766017e-05\n",
      "0.0001\n",
      "0.000316227766017\n",
      "0.001\n",
      "0.00316227766017\n",
      "0.01\n",
      "0.0316227766017\n",
      "0.1\n",
      "0.316227766017\n",
      "1.0\n",
      "3.16227766017\n",
      "10.0\n",
      "31.6227766017\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "for lamb in np.logspace(-5, 2, n):\n",
    "    print(lamb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions with ws[51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '/Users/akhileshgotmare/Desktop/Git_Junta/data-ml-course-project1/test.csv' # TODO: download train data and supply path here \n",
    "_, X_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_test = np.delete(X_test, del_features, axis=1)\n",
    "tX_test, mean_tX_test, std_tX_test = standardize(X_test)\n",
    "print(tX_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.38275805e+03,  -4.03215163e+03,  -3.00152050e+03,\n",
       "         1.63606080e+03,   3.24782312e+02,  -3.81922681e+03,\n",
       "         2.11079515e+03,  -1.08840782e+03,   8.09333759e+02,\n",
       "         1.14798053e+03,  -8.92103226e+01,   4.71066940e+01,\n",
       "         3.32241297e+03,   1.35583755e+02,   9.60290265e+01,\n",
       "        -2.61186380e+03,  -7.90142572e+00,   7.86164376e+02,\n",
       "         8.14881300e+01,   1.48100934e+03,   3.81643049e+03,\n",
       "         1.08361236e+03,   3.93780904e+03,  -1.30023583e+03,\n",
       "         1.70400500e+03,   5.32108735e+02,  -1.08884659e+02,\n",
       "        -1.39715845e+02,   3.93721606e+03,   3.67055747e+01,\n",
       "        -8.98326003e+01,  -4.67349093e+02,  -5.62990755e+03,\n",
       "         4.39407424e+03,  -8.52161695e+03,  -1.02325394e+04,\n",
       "         1.20379556e+03,  -9.15922076e+01,   1.88449419e+03,\n",
       "         3.05123229e+03,  -4.35520884e+02,   1.78417537e+02,\n",
       "         1.39180745e+03,  -7.01567136e+02,   2.28436764e+02,\n",
       "        -2.57262428e+03,   1.70998373e+02,  -5.20677363e+01,\n",
       "        -2.80558466e+02,   2.81169585e+03,  -8.13549203e+03,\n",
       "         9.35105153e+02,   5.15110287e+03,  -1.32547024e+02,\n",
       "         8.69159975e+02,   1.17765147e+02,   1.55209921e+03,\n",
       "         4.81629232e+02,   3.52568083e+03,   1.58706074e+03,\n",
       "         2.50592911e+01,   9.90559597e+01,  -1.30523972e+03,\n",
       "         5.92932158e+03,   5.74919802e+03,   2.91759442e+03,\n",
       "         3.88619321e+03,  -2.13177760e+03,  -3.26494153e+02,\n",
       "         2.13902051e+03,   2.57078294e+01,  -2.78154444e+01,\n",
       "        -1.02669253e+03,  -4.25447305e+01,  -5.64707320e+01,\n",
       "         2.12665936e+03,   1.51008157e-01,  -1.20406583e+03,\n",
       "         1.67446916e+01,  -8.12121474e+03,   1.51917538e+02,\n",
       "        -2.73783663e+03,   1.90873755e+03,   2.21306165e+02,\n",
       "         1.22995598e+03,   1.79770439e+03,   4.87033864e+01,\n",
       "         7.30078458e+01,   3.61155665e+02,   1.96746163e+01,\n",
       "         4.05916392e+01])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws[51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
