{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '/Users/akhileshgotmare/Desktop/Git_Junta/data-ml-course-project1/train.csv' # TODO: download train data and supply path here \n",
    "y, X, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "\n",
    "def standardize_badFeatures(X):\n",
    "    \n",
    "    # Function that calculate the mean and std of bad features without elements equal to -999\n",
    "    # Then, it replaces -999 values by zeros, zeros won't influence the train of the model... \n",
    "    mean_x = np.zeros((X.shape[1],))\n",
    "    std_x = np.zeros((X.shape[1],))\n",
    "    for d in range(X.shape[1]):\n",
    "        idx = np.where(X[:,d] == -999)[0]\n",
    "        mean_x[d] = np.mean(np.delete(X[:,d], (idx)))\n",
    "        std_x[d] = np.std(np.delete(X[:,d], (idx)))\n",
    "        X[:,d] = (X[:,d]-mean_x[d])/std_x[d]\n",
    "        X[idx,d] = 0\n",
    "    return X, mean_x, std_x\n",
    "\n",
    "\n",
    "def clean_data(X):\n",
    "\n",
    "    # find indices of features that have at least one value -999, we call them \"bad\" features\n",
    "    idx_badFeatures = []\n",
    "    for d in range(X.shape[1]):\n",
    "        if sum(X[:,d] == -999) > 0:\n",
    "            idx_badFeatures.append(d)\n",
    "\n",
    "    # separate \"good\" and \"bad\" features\n",
    "    X_badFeatures = X[:,idx_badFeatures]\n",
    "    X_goodFeatures = np.delete(X,(idx_badFeatures), axis=1)\n",
    "\n",
    "    # Standardize it differently (see : standardize_badFeatures(X))\n",
    "    tX, mean_x, std_x = standardize(X_goodFeatures)\n",
    "    tX2, mean_x2, std_x2 = standardize_badFeatures(X_badFeatures)\n",
    "\n",
    "    # comment the 3 next lines if you want to work only with \"good\" features\n",
    "    tX = np.hstack((tX, tX2))\n",
    "    mean_x = np.hstack((mean_x, mean_x2))\n",
    "    std_x = np.hstack((std_x, std_x2))\n",
    "    \n",
    "    return tX, mean_x, std_x\n",
    "\n",
    "# Now tX already has ones in the first column...\n",
    "tX, mean_x, std_x = clean_data(X)\n",
    "X=tX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y[np.where(y == -1)[0]] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Penalized logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sigma(a):\n",
    "    \n",
    "    sig=np.zeros([a.shape[0]],)\n",
    "    \n",
    "    for i in range(a.shape[0]):\n",
    "        if a[i]>100:\n",
    "            sig[i] = 1\n",
    "        elif a[i]<-100:\n",
    "            sig[i] = 0\n",
    "        else:\n",
    "            sig[i]=np.exp(a[i])/(1+ np.exp(a[i]))\n",
    "        \n",
    "                \n",
    "    \n",
    "    sig = np.exp(a)/(1+ np.exp(a))\n",
    "    \n",
    "    return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0 0\n",
      "0\n",
      "0 0\n",
      "1\n",
      "0 0\n",
      "2\n",
      "0 0\n",
      "3\n",
      "0 0\n",
      "4\n",
      "0 0\n",
      "5\n",
      "0 1\n",
      "0 1\n",
      "0\n",
      "0 1\n",
      "1\n",
      "0 1\n",
      "2\n",
      "0 1\n",
      "3\n",
      "0 1\n",
      "4\n",
      "0 1\n",
      "5\n",
      "0 2\n",
      "0 2\n",
      "0\n",
      "0 2\n",
      "1\n",
      "0 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akhileshgotmare/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:15: RuntimeWarning: overflow encountered in exp\n",
      "/Users/akhileshgotmare/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:15: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2\n",
      "3\n",
      "0 2\n",
      "4\n",
      "0 2\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akhileshgotmare/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:50: RuntimeWarning: invalid value encountered in greater_equal\n",
      "/Users/akhileshgotmare/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:51: RuntimeWarning: invalid value encountered in less_equal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0\n",
      "1 0\n",
      "0\n",
      "1 0\n",
      "1\n",
      "1 0\n",
      "2\n",
      "1 0\n",
      "3\n",
      "1 0\n",
      "4\n",
      "1 0\n",
      "5\n",
      "1 1\n",
      "1 1\n",
      "0\n",
      "1 1\n",
      "1\n",
      "1 1\n",
      "2\n",
      "1 1\n",
      "3\n",
      "1 1\n",
      "4\n",
      "1 1\n",
      "5\n",
      "1 2\n",
      "1 2\n",
      "0\n",
      "1 2\n",
      "1\n",
      "1 2\n",
      "2\n",
      "1 2\n",
      "3\n",
      "1 2\n",
      "4\n",
      "1 2\n",
      "5\n",
      "2 0\n",
      "2 0\n",
      "0\n",
      "2 0\n",
      "1\n",
      "2 0\n",
      "2\n",
      "2 0\n",
      "3\n",
      "2 0\n",
      "4\n",
      "2 0\n",
      "5\n",
      "2 1\n",
      "2 1\n",
      "0\n",
      "2 1\n",
      "1\n",
      "2 1\n",
      "2\n",
      "2 1\n",
      "3\n",
      "2 1\n",
      "4\n",
      "2 1\n",
      "5\n",
      "2 2\n",
      "2 2\n",
      "0\n",
      "2 2\n",
      "1\n",
      "2 2\n",
      "2\n",
      "2 2\n",
      "3\n",
      "2 2\n",
      "4\n",
      "2 2\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "\n",
    "\n",
    "m=3\n",
    "n=3\n",
    "P = np.zeros([m+1,n+1])\n",
    " \n",
    "max_degree=m-1\n",
    "gamma = 0.01\n",
    "\n",
    "import random\n",
    "import myFunctions as my\n",
    "\n",
    "\n",
    "for degree in range(1:m):\n",
    "    j=0\n",
    "    for lamb in np.logspace(-5, 2, n):\n",
    "        print(i,j)\n",
    "        \n",
    "        max_iters = 6\n",
    "        \n",
    "        nums = [x for x in range(X.shape[0])]\n",
    "        random.shuffle(nums)\n",
    "\n",
    "        #row_r1 = a[1, :] \n",
    "        stop=int(X.shape[0]/10)\n",
    "        \n",
    "        X_test = X[nums[0:stop],:]\n",
    "        X_train = X[nums[stop+1:-1],:]\n",
    "        \n",
    "        y_test = y[nums[0:stop]]\n",
    "        y_train = y[nums[stop+1:-1]]\n",
    "        \n",
    "        \n",
    "        X_test_poly = my.build_poly(X_test, degree)\n",
    "        X_train_poly = my.build_poly(X_train, degree)\n",
    "        \n",
    "        \n",
    "        initial_w=np.random.random([X_train_poly.shape[1]],)\n",
    "        w=initial_w\n",
    "        \n",
    "        for n_iter in range(max_iters):\n",
    "            \n",
    "            print(i,j)\n",
    "            print(n_iter)\n",
    "            gradient = X_train_poly.T.dot(sigma(X_train_poly.dot(w)) - y_train) + 2*lamb*w\n",
    "            w = w - gamma*gradient\n",
    "        \n",
    "        y_test_predict = X_test_poly.dot(w) \n",
    "        y_test_predict[np.where(y_test_predict >= 0.5)[0]] = 1\n",
    "        y_test_predict[np.where(y_test_predict <= 0.5)[0]] = 0\n",
    "        \n",
    "        error = len(np.nonzero(y_test_predict-y_test)[0])/len(y_test)\n",
    "        performance = 1 - error\n",
    "        \n",
    "        P[i,j] = performance\n",
    "            \n",
    "            \n",
    "        j+= 1\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akhileshgotmare/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:15: RuntimeWarning: overflow encountered in exp\n",
      "/Users/akhileshgotmare/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:15: RuntimeWarning: invalid value encountered in true_divide\n",
      "/Users/akhileshgotmare/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:31: RuntimeWarning: invalid value encountered in greater_equal\n",
      "/Users/akhileshgotmare/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:32: RuntimeWarning: invalid value encountered in less_equal\n"
     ]
    }
   ],
   "source": [
    "max_iters = 6\n",
    "        \n",
    "nums = [x for x in range(X.shape[0])]\n",
    "random.shuffle(nums)\n",
    "\n",
    "        #row_r1 = a[1, :] \n",
    "stop=int(X.shape[0]/10)\n",
    "        \n",
    "X_test = X[nums[0:stop],:]\n",
    "X_train = X[nums[stop+1:-1],:]\n",
    "        \n",
    "y_test = y[nums[0:stop]]\n",
    "y_train = y[nums[stop+1:-1]]\n",
    "        \n",
    "        \n",
    "X_test_poly = my.build_poly(X_test, degree)\n",
    "X_train_poly = my.build_poly(X_train, degree)\n",
    "        \n",
    "        \n",
    "initial_w=np.random.random([X_train_poly.shape[1]],)\n",
    "w=initial_w\n",
    "        \n",
    "for n_iter in range(1):\n",
    "    print(i,j)\n",
    "    print(n_iter)\n",
    "    gradient = X_train_poly.T.dot(sigma(X_train_poly.dot(w)) - y_train) + 2*lamb*w\n",
    "    w_old=w\n",
    "    w = w - gamma*gradient\n",
    "        \n",
    "    y_test_predict = X_test_poly.dot(w) \n",
    "    y_test_predict[np.where(y_test_predict >= 0.5)[0]] = 1\n",
    "    y_test_predict[np.where(y_test_predict <= 0.5)[0]] = 0\n",
    "        \n",
    "    error = len(np.nonzero(y_test_predict-y_test)[0])/len(y_test)\n",
    "    performance = 1 - error\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_poly.T.dot(sigma(X_train_poly.dot(w)) - y_train) + 2*lamb*w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ nan,  nan,  nan, ...,  nan,  nan,  nan])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_poly.dot(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_old.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = X_train_poly.dot(w_old)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
